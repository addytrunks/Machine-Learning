{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c1d2ef4-a14b-4de7-8e2a-2a9646f7e0f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:32:38.044942Z",
     "start_time": "2024-06-18T07:32:35.405320Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "# To use pytorch's built-in datasets\n",
    "from torchvision import datasets\n",
    "# To transform PIL image to tensor\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8128dee-0afe-4275-a552-589b741627f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Getting a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fd3051f-3c7b-4c68-82ee-86e670a881e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:32:38.091128Z",
     "start_time": "2024-06-18T07:32:38.044942Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(train=True, root='data', download=True, transform=transforms.ToTensor(),\n",
    "                                   target_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08267582-1cc3-45c0-84c1-36188d2593d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:32:38.104200Z",
     "start_time": "2024-06-18T07:32:38.091128Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = datasets.FashionMNIST(train=False, root='data', download=True, transform=transforms.ToTensor(),\n",
    "                                  target_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69a9fe50-706e-4040-bdbc-bd19f59c849f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:32:38.123140Z",
     "start_time": "2024-06-18T07:32:38.105205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "           0.0157, 0.0000, 0.0000, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0471, 0.0392, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "           0.3020, 0.5098, 0.2824, 0.0588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "           0.5529, 0.3451, 0.6745, 0.2588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "           0.4824, 0.7686, 0.8980, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "           0.8745, 0.9608, 0.6784, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "           0.8627, 0.9529, 0.7922, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "           0.8863, 0.7725, 0.8196, 0.2039],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "           0.9608, 0.4667, 0.6549, 0.2196],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "           0.8510, 0.8196, 0.3608, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "           0.8549, 1.0000, 0.3020, 0.0000],\n",
       "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "           0.8784, 0.9569, 0.6235, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "           0.9137, 0.9333, 0.8431, 0.0000],\n",
       "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "           0.8627, 0.9098, 0.9647, 0.0000],\n",
       "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "           0.8706, 0.8941, 0.8824, 0.0000],\n",
       "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "           0.8745, 0.8784, 0.8980, 0.1137],\n",
       "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "           0.8627, 0.8667, 0.9020, 0.2627],\n",
       "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "           0.7098, 0.8039, 0.8078, 0.4510],\n",
       "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "           0.6549, 0.6941, 0.8235, 0.3608],\n",
       "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "           0.7529, 0.8471, 0.6667, 0.0000],\n",
       "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "           0.3882, 0.2275, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f7833-d2f2-4ab7-84e3-13da154b84eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Checking the input and output shapes of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2df3d9bf-05d2-45ba-b394-94d9469cba09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:32:38.128764Z",
     "start_time": "2024-06-18T07:32:38.123140Z"
    }
   },
   "outputs": [],
   "source": [
    "class_to_idx = train_data.class_to_idx\n",
    "class_names = train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "193591d5-fe3b-4d41-bd0a-e4bc1e01d6ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:32:38.138106Z",
     "start_time": "2024-06-18T07:32:38.128764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the image: torch.Size([1, 28, 28]) -> [color channels, height, width]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of the image: {image.shape} -> [color channels, height, width]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692b9a5d-ad18-4993-9ac2-91520381db07",
   "metadata": {},
   "source": [
    "### Visualising our image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7974f16f-1cec-44e8-af82-1f8137e4a5c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:32:38.298477Z",
     "start_time": "2024-06-18T07:32:38.138106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "# Matplotlib expects the image in the format (h,w,c) and as for gray scale it doesn't expect color channel\n",
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90217a33-866c-442a-a13a-e238af4f3234",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Prepare Dataloader\n",
    "\n",
    "Turns our dataset into python iterable\n",
    "\n",
    "More specifically, we want to turn our data into mini-batches.\n",
    "\n",
    "We do this:\n",
    "1. Computationally Efficient\n",
    "2. Gives our neural network to update its gradients per epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "910493a0-71a5-4fc0-a9e5-1eb78b30459c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:32:38.306213Z",
     "start_time": "2024-06-18T07:32:38.298477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x24d3ff22d90>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x24d3fed1990>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b07b494b-b3bc-4345-8d38-d2e6a7cbd810",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:32:38.310878Z",
     "start_time": "2024-06-18T07:32:38.306213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train : 1875 batches of 32 | Length of test : 313 batches of 32\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Length of train : {len(train_dataloader)} batches of 32 | Length of test : {len(test_dataloader)} batches of 32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47fc3a61-d25c-41fd-92a8-ba837e1bb1af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:32:38.325661Z",
     "start_time": "2024-06-18T07:32:38.310878Z"
    }
   },
   "outputs": [],
   "source": [
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc996272-eed1-4104-b449-10d300140a6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:32:38.465092Z",
     "start_time": "2024-06-18T07:32:38.325661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a sample\n",
    "torch.manual_seed(42)\n",
    "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "image, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2395fa-d793-498f-b3e9-be7a808c85ad",
   "metadata": {},
   "source": [
    "## Build a baseline model (improve upon experimentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d20d84d-ff8d-4a95-92f6-0a4c082c24ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:32:38.475394Z",
     "start_time": "2024-06-18T07:32:38.467604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before flattening : torch.Size([1, 28, 28]) -> [c,h,w]\n",
      "Shape after flattening : torch.Size([1, 784]) -> [c,h*w]\n"
     ]
    }
   ],
   "source": [
    "flatten_model = nn.Flatten()\n",
    "\n",
    "x = train_features_batch[0]\n",
    "\n",
    "output = flatten_model(x)\n",
    "\n",
    "print(f\"Shape before flattening : {x.shape} -> [c,h,w]\")\n",
    "print(f\"Shape after flattening : {output.shape} -> [c,h*w]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "196391f1-a691-4424-8c97-560ea666c874",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T07:32:38.480525Z",
     "start_time": "2024-06-18T07:32:38.477056Z"
    }
   },
   "outputs": [],
   "source": [
    "class FashionMNISTV0(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_shape:int,\n",
    "                 hidden_units:int,\n",
    "                 output_shape:int\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape,out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units,out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b155df3-dce2-40ac-9e61-538a1a9c1d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTV0(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model_0 = FashionMNISTV0(\n",
    "    input_shape=784, # this is 28*28,\n",
    "    hidden_units=10,\n",
    "    output_shape=len(class_names)\n",
    ")\n",
    "model_0.to('cpu')\n",
    "\n",
    "model_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf060b0-bafe-43e2-bbc3-41a3544ca0dc",
   "metadata": {},
   "source": [
    "### Setup loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2df1abf3-bf1a-43d4-a2aa-89fc9066659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d30571fb-8ee7-4b2f-b2a5-b73dbbc4040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_0.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16cfa32-2037-46b2-8155-64a09f0a2ab7",
   "metadata": {},
   "source": [
    "### Creating a function to time our experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cd225f8-f383-4720-aa1b-e2d67670138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start:float,\n",
    "                     end:float,\n",
    "                     device:torch.device=None\n",
    "                    ):\n",
    "    total_time = end-start\n",
    "    print(f\"Train time on {device} : {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "527ae6e7-130d-4337-8f40-f1aa90f991f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"start_timer = timer()\\nend_timer = timer()\\n\\nprint_train_time(start_timer,end_timer,device='gpu')\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''start_timer = timer()\n",
    "end_timer = timer()\n",
    "\n",
    "print_train_time(start_timer,end_timer,device='gpu')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97440791-80e1-46fc-bd68-1b3532b4c471",
   "metadata": {},
   "source": [
    "### Creating a training and testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7b34de1-2e17-4c11-a520-ee908e167084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e0d03074e14a7ca287572e79bc4e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-------\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n",
      "\n",
      "Train loss: 0.59039 | Test loss: 0.50954, Test acc: 82.04%\n",
      "\n",
      "Epoch: 1\n",
      "-------\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n",
      "\n",
      "Train loss: 0.47633 | Test loss: 0.47989, Test acc: 83.20%\n",
      "\n",
      "Epoch: 2\n",
      "-------\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n",
      "\n",
      "Train loss: 0.45503 | Test loss: 0.47664, Test acc: 83.43%\n",
      "\n",
      "Train time on cpu : 20.665 seconds\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-------\")\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    # Loop through training data\n",
    "    for batch, (X,y) in enumerate(train_dataloader):\n",
    "        model_0.train()\n",
    "\n",
    "        # 1. Forward Pass\n",
    "        y_pred = model_0(X)\n",
    "\n",
    "        # 2. Calculate loss (per batch)\n",
    "        loss = loss_fn(y_pred,y)\n",
    "        train_loss+=loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 3. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 4. optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    # Testing\n",
    "    test_loss,test_acc = 0,0\n",
    "    model_0.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X_test,y_test in test_dataloader:\n",
    "            test_pred = model_0(X_test)\n",
    "            \n",
    "            test_loss+=loss_fn(test_pred,y_test)\n",
    "\n",
    "            test_acc+=accuracy_fn(y_true=y_test,y_pred=test_pred.argmax(dim=1))\n",
    "\n",
    "        test_loss/=len(test_dataloader)\n",
    "\n",
    "        test_acc/=len(test_dataloader)\n",
    "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu, \n",
    "                                           end=train_time_end_on_cpu,\n",
    "                                           device=str(next(model_0.parameters()).device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df00f84-82e5-4220-bad7-8ac934ca084a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "624657e2-3d80-4666-ba81-7b833169f24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66b3786f-b8b9-4ca4-9ba3-fc562a71ca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "def eval_model(model:torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              loss_fn:torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "               device:torch.device = device\n",
    "              ):\n",
    "    \"\"\" Returns a dictionary of model results\"\"\"\n",
    "    loss,acc = 0,0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X,y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # Make predictions\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # Accumulate loss per batch\n",
    "            loss+= loss_fn(y_pred,y)\n",
    "            acc+= accuracy_fn(y_true=y,y_pred=y_pred.argmax(dim=1))\n",
    "        loss/=len(data_loader)\n",
    "        acc/=len(data_loader)\n",
    "\n",
    "    return {\"model_name\":model.__class__.__name__,\n",
    "            \"model_loss\":loss.item(),\n",
    "            \"model_acc\":acc,\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40c00ac9-6491-4606-897e-81fb31e592f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTV0',\n",
       " 'model_loss': 0.47663894295692444,\n",
       " 'model_acc': 83.42651757188499}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_results = eval_model(model_0,test_dataloader,loss_fn,accuracy_fn)\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80915f77-1850-490e-899a-19222bca47ad",
   "metadata": {},
   "source": [
    "## Setup device agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29e579a0-db36-4364-8486-e056e80f034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f9735f8-f91e-4b1c-ae8d-aef0098525aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTV1(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_shape:int,\n",
    "                 hidden_units:int,\n",
    "                 output_shape:int\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape,out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units,out_features=output_shape),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9d6cbfb-499c-4808-885e-566613cdb46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model_1 = FashionMNISTV1(input_shape=784,hidden_units=10,output_shape=len(class_names)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e78ad49-7bde-43a9-a138-cee37a96ffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_1.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5247b380-0390-4c08-82c2-bf1238aac879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # Send data to GPU\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1)) # Go from logits -> pred labels\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "187d3ec0-3563-4c7b-ab71-24c41fabe63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(data_loader: torch.utils.data.DataLoader,\n",
    "              model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.to(device)\n",
    "    model.eval() # put model in eval mode\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode(): \n",
    "        for X, y in data_loader:\n",
    "            # Send data to GPU\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "            \n",
    "            # 2. Calculate loss and accuracy\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y,\n",
    "                y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels\n",
    "            )\n",
    "        \n",
    "        # Adjust metrics and print out\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4621394-70aa-4a90-bfe5-63be8daf948e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf88c2a5d6e4102bd5c316f806f846e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:0--------------\n",
      "Train loss: 1.09199 | Train accuracy: 61.34%\n",
      "Test loss: 0.95636 | Test accuracy: 65.00%\n",
      "\n",
      "Epochs:1--------------\n",
      "Train loss: 0.78101 | Train accuracy: 71.93%\n",
      "Test loss: 0.72227 | Test accuracy: 73.91%\n",
      "\n",
      "Epochs:2--------------\n",
      "Train loss: 0.67027 | Train accuracy: 75.94%\n",
      "Test loss: 0.68500 | Test accuracy: 75.02%\n",
      "\n",
      "Train time on cuda : 39.506 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epochs:{epoch}--------------\")\n",
    "    train_step(data_loader=train_dataloader, \n",
    "        model=model_1, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn\n",
    "    )\n",
    "    test_step(data_loader=test_dataloader,\n",
    "        model=model_1,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn\n",
    "    )\n",
    "train_time_end_on_gpu = timer()\n",
    "total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,\n",
    "                                            end=train_time_end_on_gpu,\n",
    "                                            device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc40b98e-d5f5-48f7-883c-9701fbd1f79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTV1',\n",
       " 'model_loss': 0.6850008368492126,\n",
       " 'model_acc': 75.01996805111821}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_results = eval_model(accuracy_fn=accuracy_fn,data_loader=test_dataloader,model=model_1,loss_fn=loss_fn,device=\"cuda\")\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0175aef-7244-44dd-90d4-eaebe1144968",
   "metadata": {},
   "source": [
    "## Building a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "282ce35b-af14-4947-b3d2-1341eb924d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "94208ef7-311c-43ae-bf10-c9675613c90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTV2(nn.Module):\n",
    "    # input_shape for cnn is the no of color channels\n",
    "    def __init__(self,input_shape:int,hidden_units:int,output_shape:int):\n",
    "        super().__init__()\n",
    "\n",
    "        # The first two blocks will learn/study features from the images\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,out_channels=hidden_units,kernel_size=3,padding=1,stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,kernel_size=3,padding=1,stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,kernel_size=3,padding=1,stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,kernel_size=3,padding=1,stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*7*7,out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f7b5ef2f-23c5-428f-9b9f-cc99c9924108",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model_2 = FashionMNISTV2(input_shape=1,output_shape=len(class_names),hidden_units=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "db3e4cb2-531d-4339-97aa-e1b40b6dd358",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_2.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "45b95f9e-9886-41b4-9070-f9ac0c3a7b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad328c5a97b6417684cac713318dd20e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "---------\n",
      "Train loss: 0.60070 | Train accuracy: 78.25%\n",
      "Test loss: 0.38804 | Test accuracy: 86.33%\n",
      "\n",
      "Epoch: 1\n",
      "---------\n",
      "Train loss: 0.35925 | Train accuracy: 86.99%\n",
      "Test loss: 0.34650 | Test accuracy: 87.39%\n",
      "\n",
      "Epoch: 2\n",
      "---------\n",
      "Train loss: 0.31927 | Train accuracy: 88.38%\n",
      "Test loss: 0.31140 | Test accuracy: 89.13%\n",
      "\n",
      "Train time on cpu : 80.992 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_model_2 = timer()\n",
    "\n",
    "# Train and test model \n",
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    train_step(data_loader=train_dataloader, \n",
    "        model=model_2, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device='cpu'\n",
    "    )\n",
    "    test_step(data_loader=test_dataloader,\n",
    "        model=model_2,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device='cpu'\n",
    "    )\n",
    "\n",
    "train_time_end_model_2 = timer()\n",
    "total_train_time_model_2 = print_train_time(start=train_time_start_model_2,\n",
    "                                           end=train_time_end_model_2,\n",
    "                                           device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e82a380c-73bb-40de-aa55-a039f101abac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTV2',\n",
       " 'model_loss': 0.31139636039733887,\n",
       " 'model_acc': 89.12739616613419}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_results = eval_model(\n",
    "    model=model_2,\n",
    "    data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    accuracy_fn=accuracy_fn\n",
    ")\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "48712790-a44a-43d9-abf7-4c21d68b5bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_loss</th>\n",
       "      <th>model_acc</th>\n",
       "      <th>training_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FashionMNISTV0</td>\n",
       "      <td>0.476639</td>\n",
       "      <td>83.426518</td>\n",
       "      <td>20.665286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FashionMNISTV1</td>\n",
       "      <td>0.685001</td>\n",
       "      <td>75.019968</td>\n",
       "      <td>39.505747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FashionMNISTV2</td>\n",
       "      <td>0.311396</td>\n",
       "      <td>89.127396</td>\n",
       "      <td>80.992209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model_name  model_loss  model_acc  training_time\n",
       "0  FashionMNISTV0    0.476639  83.426518      20.665286\n",
       "1  FashionMNISTV1    0.685001  75.019968      39.505747\n",
       "2  FashionMNISTV2    0.311396  89.127396      80.992209"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "compare_results = pd.DataFrame([model_0_results, model_1_results, model_2_results])\n",
    "# Add training times to results comparison\n",
    "compare_results[\"training_time\"] = [total_train_time_model_0,\n",
    "                                    total_train_time_model_1,\n",
    "                                    total_train_time_model_2]\n",
    "compare_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

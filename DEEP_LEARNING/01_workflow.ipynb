{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7135b71d-edb0-41c6-b880-c66f37c25de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4960d6d-0669-49c9-b52f-210774d77959",
   "metadata": {},
   "source": [
    "What is going to be covered:\n",
    " 1. Data Pre-processing\n",
    " 2. Build Model\n",
    " 3. Fit model to data(training)\n",
    " 4. Making prediction and evaluating a model\n",
    " 5. Saving & loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5894b4c3-0e9d-465f-b830-0b8cd9740086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn stands for neural network and this package contains the basic building blocks for creating neural networks in PyTorch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45d81ea-1376-4b9e-b366-4e265eb33f57",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data (preparing and loading)\n",
    "ML consists of two parts:\n",
    "1. Feeding the model numerical data\n",
    "2. Model learns patterns in that numerical representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ce61a10d-ad07-4b92-8cbb-8ddbcf8afd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regressor (mock)\n",
    "\n",
    "# Known parameters\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "# Create\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "\n",
    "\n",
    "X = torch.arange(start,end,step).unsqueeze(dim=1)\n",
    "y = weight*X+bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "33b5ab0a-a220-4002-ad7b-527cf15bd1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000],\n",
       "        [0.0200],\n",
       "        [0.0400],\n",
       "        [0.0600],\n",
       "        [0.0800],\n",
       "        [0.1000],\n",
       "        [0.1200],\n",
       "        [0.1400],\n",
       "        [0.1600],\n",
       "        [0.1800],\n",
       "        [0.2000],\n",
       "        [0.2200],\n",
       "        [0.2400],\n",
       "        [0.2600],\n",
       "        [0.2800],\n",
       "        [0.3000],\n",
       "        [0.3200],\n",
       "        [0.3400],\n",
       "        [0.3600],\n",
       "        [0.3800],\n",
       "        [0.4000],\n",
       "        [0.4200],\n",
       "        [0.4400],\n",
       "        [0.4600],\n",
       "        [0.4800],\n",
       "        [0.5000],\n",
       "        [0.5200],\n",
       "        [0.5400],\n",
       "        [0.5600],\n",
       "        [0.5800],\n",
       "        [0.6000],\n",
       "        [0.6200],\n",
       "        [0.6400],\n",
       "        [0.6600],\n",
       "        [0.6800],\n",
       "        [0.7000],\n",
       "        [0.7200],\n",
       "        [0.7400],\n",
       "        [0.7600],\n",
       "        [0.7800],\n",
       "        [0.8000],\n",
       "        [0.8200],\n",
       "        [0.8400],\n",
       "        [0.8600],\n",
       "        [0.8800],\n",
       "        [0.9000],\n",
       "        [0.9200],\n",
       "        [0.9400],\n",
       "        [0.9600],\n",
       "        [0.9800]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0be24bd8-4b87-4a75-99c1-bf7057b9efee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3000],\n",
       "        [0.3140],\n",
       "        [0.3280],\n",
       "        [0.3420],\n",
       "        [0.3560],\n",
       "        [0.3700],\n",
       "        [0.3840],\n",
       "        [0.3980],\n",
       "        [0.4120],\n",
       "        [0.4260],\n",
       "        [0.4400],\n",
       "        [0.4540],\n",
       "        [0.4680],\n",
       "        [0.4820],\n",
       "        [0.4960],\n",
       "        [0.5100],\n",
       "        [0.5240],\n",
       "        [0.5380],\n",
       "        [0.5520],\n",
       "        [0.5660],\n",
       "        [0.5800],\n",
       "        [0.5940],\n",
       "        [0.6080],\n",
       "        [0.6220],\n",
       "        [0.6360],\n",
       "        [0.6500],\n",
       "        [0.6640],\n",
       "        [0.6780],\n",
       "        [0.6920],\n",
       "        [0.7060],\n",
       "        [0.7200],\n",
       "        [0.7340],\n",
       "        [0.7480],\n",
       "        [0.7620],\n",
       "        [0.7760],\n",
       "        [0.7900],\n",
       "        [0.8040],\n",
       "        [0.8180],\n",
       "        [0.8320],\n",
       "        [0.8460],\n",
       "        [0.8600],\n",
       "        [0.8740],\n",
       "        [0.8880],\n",
       "        [0.9020],\n",
       "        [0.9160],\n",
       "        [0.9300],\n",
       "        [0.9440],\n",
       "        [0.9580],\n",
       "        [0.9720],\n",
       "        [0.9860]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db073ff-b757-4300-b7bb-f812e05654b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "97e06067-518b-47ab-830d-9a2a23c878df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4928cec5-619e-4794-8d40-3716183a9f85",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Visualising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb602995-3e51-48b7-b394-72c1e1853447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=X_train, \n",
    "                     train_labels=y_train, \n",
    "                     test_data=X_test, \n",
    "                     test_labels=y_test, \n",
    "                     predictions=None):\n",
    "  \"\"\"\n",
    "  Plots training data, test data and compares predictions.\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(10, 7))\n",
    "\n",
    "  # Plot training data in blue\n",
    "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "  \n",
    "  # Plot test data in green\n",
    "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
    "\n",
    "  if predictions is not None:\n",
    "    # Plot the predictions in red (predictions were made on the test data)\n",
    "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "\n",
    "  # Show the legend\n",
    "  plt.legend(prop={\"size\": 14});\n",
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0758d9-c420-4434-82a4-eb5f39a35077",
   "metadata": {},
   "source": [
    "## Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3f0c60-f769-4243-b9fb-783c32b14e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressorModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # weights and bias(model parameters) are the parameters of a neural network which will help in improving the model's accuracy of producing an output.\n",
    "        self.weight =nn.Parameter(torch.randn(1,requires_grad=True,dtype=torch.float))\n",
    "        self.bias= nn.Parameter(torch.randn(1,requires_grad=True,dtype=torch.float))\n",
    "\n",
    "    # Computation for output\n",
    "    def forward(self,x:torch.Tensor) -> torch.Tensor:\n",
    "        return self.weight*x+self.bias\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7785a1ad-cb83-483b-9d16-5e371b853d78",
   "metadata": {},
   "source": [
    "### Cheking the internals of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b2e80-cfb3-48fe-a1cc-99365f51295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_0 = LinearRegressorModel()\n",
    "\n",
    "# Check out the parameters\n",
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f275d75-9c1f-4af1-81c9-8d7425b30e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list named parameters\n",
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424b769f-aaa4-4ad6-89c1-9020b6d67dda",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfce7ba-57eb-4df2-a0b9-47d98dd6771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When predicting/inferencing, the model need not keep track of gradient (which is done in training) -> .inference_mode() does that (stop tracking \n",
    "# gradients)\n",
    "with torch.inference_mode():\n",
    "    y_pred = model_0(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9827b99d-420f-40f0-a616-7d057892645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(predictions=y_pred)\n",
    "\n",
    "# It can be noticed that the y_pred and y_test(actual) do  not overlap which says that the parameters of the model needs to updated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8304129e-5761-474b-b4ac-ee56d7c3a9ea",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "For our model to update its parameters on its own, we'll need to add a few more things to our recipe.\n",
    "\n",
    "And that's a loss function as well as an optimizer.\n",
    "\n",
    "* **Loss Function**:Measures how wrong the model's predictions are. Lower the better.\n",
    "* **Optimizer**:Takes into account the loss of the model. Adjust the parameters of the model (weights and bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff0af8-7f40-4aed-b085-41aacae2ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(model_0.parameters(),lr=0.01)\n",
    "\n",
    "# lr => learning rate => determines how big the changes in the parameter should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959e6850-9baf-4ed9-9127-002dda7de430",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Set the number of epochs (how many times the model will pass over the training data)\n",
    "epochs = 100\n",
    "\n",
    "# Create empty loss lists to track values\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "epoch_count = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "\n",
    "    # Put model in training mode (this is the default state of a model)\n",
    "    model_0.train()\n",
    "\n",
    "    # 1. Forward pass on train data using the forward() method inside \n",
    "    y_pred = model_0(X_train)\n",
    "\n",
    "    # 2. Calculate the loss (how different are our models predictions to the ground truth)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # 3. Zero grad of the optimizer\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Progress the optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    model_0.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "      # 1. Forward pass on test data\n",
    "      test_pred = model_0(X_test)\n",
    "\n",
    "      # 2. Caculate loss on test data\n",
    "      test_loss = loss_fn(test_pred, y_test.type(torch.float)) # predictions come in torch.float datatype, so comparisons need to be done with tensors of the same type\n",
    "\n",
    "      # Print out what's happening\n",
    "      if epoch % 10 == 0:\n",
    "            epoch_count.append(epoch)\n",
    "            train_loss_values.append(loss.detach().numpy())\n",
    "            test_loss_values.append(test_loss.detach().numpy())\n",
    "            print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cf71d4-0bd2-4d15-9702-9be2bee29077",
   "metadata": {},
   "source": [
    "### Visualise the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73efb9f5-5bec-4f77-864d-70e4aa5f4cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    y_pred = model_0(X_test)\n",
    "    plot_predictions(predictions=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0976dbb6-85a1-4924-ad1a-21e8c29d6a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48108b8b-d98c-409f-9ffd-3b0eba71d1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight,bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26259b1-f911-4001-bbc0-dbaf75bc3b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss curves\n",
    "plt.plot(epoch_count, train_loss_values, label=\"Train loss\")\n",
    "plt.plot(epoch_count, test_loss_values, label=\"Test loss\")\n",
    "plt.title(\"Training and test loss curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

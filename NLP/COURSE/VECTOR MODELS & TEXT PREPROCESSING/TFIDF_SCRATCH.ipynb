{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2b69a40-a84c-4eb2-b574-560ab3c69be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import random\n",
    "\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7571fd8d-6a14-4860-a746-e6fb2be20538",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\adhri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92a4ef9d-5318-4e55-9745-d5e3a51e1273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"bbc_text_cls.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3995eff7-7979-4612-8e36-aa5803392817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate word2idx\n",
    "idx = 0\n",
    "word2idx = {}\n",
    "# will contain the index of each word in each document.\n",
    "tokenized_docs = []\n",
    "\n",
    "for doc in df['text']:\n",
    "    words = word_tokenize(doc.lower())\n",
    "    doc_as_int = []\n",
    "\n",
    "    for word in words:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = idx\n",
    "            idx+=1\n",
    "\n",
    "        #appending the index of the word in the document\n",
    "        doc_as_int.append(word2idx[word])\n",
    "    tokenized_docs.append(doc_as_int)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "704964b2-f9ee-4c65-a9c5-eda4366d8416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse mapping\n",
    "idx2word = {v:k for k,v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1f1cd2f-4fdd-4783-b7a8-cf4f95f8d90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of documents\n",
    "N = len(df['text'])\n",
    "v = len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9757c92-64ed-4f3d-9e56-f299c5e4d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = np.zeros((N,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f6d2fdd-d891-4d19-b64b-43e25b71d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looping through ith(row) document\n",
    "for i, doc_as_int in enumerate(tokenized_docs):\n",
    "    # looping through jth (column) index of the word in ith document \n",
    "    for j in doc_as_int:\n",
    "        tf[i,j]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45b45a80-cdd0-4b72-9d96-2ef19b655edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34762,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_freq = np.sum(tf>0,axis=0)\n",
    "idf = np.log(N/document_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ccf93fb-e3fd-4f3c-bf06-0f32860650d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = tf*idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "666e11aa-cd5e-4c73-b306-8de619c5166e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: politics\n",
      "Text: Observers to monitor UK election\n",
      "Top 5 terms:\n",
      "registration\n",
      "electoral\n",
      "observers\n",
      "election\n",
      "fraud\n"
     ]
    }
   ],
   "source": [
    "# pick a random document, show the top 5 terms (in terms of tf_idf score)\n",
    "i = np.random.choice(N)\n",
    "row = df.iloc[i]\n",
    "print(\"Label:\", row['labels'])\n",
    "print(\"Text:\", row['text'].split(\"\\n\", 1)[0])\n",
    "print(\"Top 5 terms:\")\n",
    "\n",
    "scores = tf_idf[i]\n",
    "indices = (-scores).argsort()\n",
    "\n",
    "for j in indices[:5]:\n",
    "  print(idx2word[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a51a46-95b9-4b84-94d1-52f3c29d5d27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
